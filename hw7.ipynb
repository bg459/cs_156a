{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "A lot of setup is needed from HW 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_table('http://work.caltech.edu/data/in.dta', delim_whitespace = True, header = None)\n",
    "test = pd.read_table('http://work.caltech.edu/data/out.dta', delim_whitespace = True, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Creating the Data\n",
    "import random\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# randomly generates a point\n",
    "        \n",
    "X = np.array(train)\n",
    "Y = list(X[:, -1])\n",
    "X = np.delete(X, -1, axis = 1)\n",
    "\n",
    "new_X = np.zeros((X.shape[0], 5))\n",
    "\n",
    "new_X[:, 0] = X[:, 0] **2\n",
    "new_X[:, 1] = X[:, 1] **2\n",
    "new_X[:, 2] = X[:, 0] * X[:, 1]\n",
    "new_X[:, 3] = abs(X[:, 0] - X[:, 1])\n",
    "new_X[:, 4] = abs(X[:, 0] + X[:, 1])\n",
    "X = np.concatenate((X, new_X), axis = 1)\n",
    "x_0 = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((x_0, X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.5\n",
      "0.2\n",
      "0.0\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 25, shuffle = False)\n",
    "\n",
    "for k in range(3, 8):\n",
    "    X_temp = X_train[:, 0:k+1]\n",
    "    X_t = X_test[:, 0:k+1]\n",
    "    \n",
    "    reg = LinearRegression().fit(X_temp, y_train)\n",
    "    guess = reg.predict(X_t)\n",
    "    guess = np.sign(guess)\n",
    "    \n",
    "    diff = np.abs(guess - y_test)\n",
    "    print((diff == 2).sum()/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "0.416\n",
      "0.188\n",
      "0.084\n",
      "0.072\n"
     ]
    }
   ],
   "source": [
    "## Test on test set\n",
    "\n",
    "# Clean test set:\n",
    "def make_test(test):\n",
    "    X = np.array(test)\n",
    "    Y = list(X[:, -1])\n",
    "    X = np.delete(X, -1, axis = 1)\n",
    "\n",
    "    new_X = np.zeros((X.shape[0], 5))\n",
    "\n",
    "    new_X[:, 0] = X[:, 0] **2\n",
    "    new_X[:, 1] = X[:, 1] **2\n",
    "    new_X[:, 2] = X[:, 0] * X[:, 1]\n",
    "    new_X[:, 3] = abs(X[:, 0] - X[:, 1])\n",
    "    new_X[:, 4] = abs(X[:, 0] + X[:, 1])\n",
    "    X = np.concatenate((X, new_X), axis = 1)\n",
    "    x_0 = np.ones((X.shape[0], 1))\n",
    "    X = np.concatenate((x_0, X), axis = 1)\n",
    "    return X, Y\n",
    "\n",
    "Xtest, Ytest = make_test(test)\n",
    "\n",
    "for k in range(3, 8):\n",
    "    X_temp = X_train[:, 0:k+1]\n",
    "    X_t = Xtest[:, 0:k+1]\n",
    "    \n",
    "    reg = LinearRegression(fit_intercept = False).fit(X_temp, y_train)\n",
    "    guess = reg.predict(X_t)\n",
    "    guess = np.sign(guess)\n",
    "    print(np.mean(guess != Ytest))\n",
    "\n",
    "## E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.9\n",
      "0.5\n",
      "0.2\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X_test, X_train, y_test, y_train\n",
    "\n",
    "for k in range(3, 8):\n",
    "    X_temp = X_train[:, 0:k+1]\n",
    "    X_t = X_test[:, 0:k+1]\n",
    "    \n",
    "    reg = LinearRegression().fit(X_temp, y_train)\n",
    "    guess = reg.predict(X_t)\n",
    "    guess = np.sign(guess)\n",
    "    \n",
    "    diff = np.abs(guess - y_test)\n",
    "    print((diff == 2).sum()/10)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = X_test, X_train, y_test, y_train\n",
    "\n",
    "## D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396\n",
      "0.388\n",
      "0.284\n",
      "0.192\n",
      "0.196\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X_test, X_train, y_test, y_train\n",
    "\n",
    "\n",
    "Xtest, Ytest = make_test(test)\n",
    "\n",
    "for k in range(3, 8):\n",
    "    X_temp = X_train[:, 0:k+1]\n",
    "    X_t = Xtest[:, 0:k+1]\n",
    "    \n",
    "    reg = LinearRegression(fit_intercept = False).fit(X_temp, y_train)\n",
    "    guess = reg.predict(X_t)\n",
    "    guess = np.sign(guess)\n",
    "    print(np.mean(guess != Ytest))\n",
    "X_train, X_test, y_train, y_test = X_test, X_train, y_test, y_train\n",
    "## D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is from the previous code: 0.1, and 0.2: Choose B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3324733018714351"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected of e_1 and e_2 is obviously 0.5\n",
    "# I think you need some pdf to get this analytically, but I am bad :( \n",
    "# So we will just simulate\n",
    "\n",
    "import random\n",
    "nsims = 20000\n",
    "total = 0\n",
    "for _ in range(nsims):\n",
    "    a = random.uniform(0, 1)\n",
    "    b = random.uniform(0, 1)\n",
    "    total += min(a, b)\n",
    "total/nsims\n",
    "\n",
    "## Probably 1/3, just choose D until we get smarter..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem you have to find the leave-out-out errors. For the constant case its easy, it is just 1/4 + 1/4 + 1, which averages out to 3/2.\n",
    "\n",
    "We need the same for the other case. When you leave out (1,0), you predict using the linear model (1, 2/p+1). When you leave out (-1, 0) you predict using the model (-1, 2/p-1). When you leave out (p, 1) your error is just 1 like in the previous case (same model)\n",
    "\n",
    "So we have that $\\frac{4}{(p+1)^2} + \\frac{4}{(p-1)^2} = 1/2$, then you solve to get C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Inheriting some code from HW #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# randomly generates a point\n",
    "def generate_point():\n",
    "    x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "    return (x, y)\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def target_function(self, x):\n",
    "        if x[0] * self.target_m + self.target_b > x[1]:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1    \n",
    "\n",
    "\n",
    "    def __init__(self, num_points):\n",
    "        p0 = generate_point()\n",
    "        p1 = generate_point()\n",
    "        self.target_m = (p1[1] - p0[1]) / (p1[0] - p0[0])\n",
    "        self.target_b = p0[1] - self.target_m * p0[0]\n",
    "\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i in range(num_points):\n",
    "            pt = generate_point()\n",
    "            self.X.append(pt)\n",
    "            self.Y.append(self.target_function(pt))\n",
    "\n",
    "    def plot(self):\n",
    "        cs = [\"red\" if y > 0 else \"blue\" for y in self.Y]\n",
    "        plt.scatter([x[0] for x in self.X], [x[1] for x in self.X], c=cs)\n",
    "        plt.plot((-1, 1), \n",
    "                 (-self.target_m+self.target_b, self.target_m+self.target_b))\n",
    "        plt.gca().set_aspect(1)\n",
    "        plt.xlim([-1, 1])\n",
    "        plt.ylim([-1, 1])\n",
    "        plt.title(\"Target function\")\n",
    "        plt.show()\n",
    "\n",
    "class PLA:\n",
    "    def evaluate(self, p):\n",
    "        return int(np.sign(self.w[0]*1 + self.w[1]*p[0] + self.w[2]*p[1]))\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.w = [0,0,0]\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def fit(self, plot_iters = False):\n",
    "        self.w = np.array([0,0,0])\n",
    "        num_iters = 0\n",
    "\n",
    "        while True:\n",
    "            missed = []\n",
    "            for (x,y) in zip(self.dataset.X, self.dataset.Y):\n",
    "                if self.evaluate(x) != y:\n",
    "                    missed.append((np.array([1, x[0], x[1]]), y))\n",
    "            if len(missed) > 0:\n",
    "                num_iters += 1\n",
    "                (x,y) = random.choice(missed)\n",
    "                self.w = self.w + y * x \n",
    "                \n",
    "            else: \n",
    "                if plot_iters:\n",
    "                    self.plot()\n",
    "                return num_iters\n",
    "\n",
    "    def plot(self):\n",
    "        cs = [\"red\" if y > 0 else \"blue\" for y in self.dataset.Y]\n",
    "        plt.scatter([x[0] for x in self.dataset.X], [x[1] for x in self.dataset.X], c=cs)\n",
    "        y_left = (self.w[1] - self.w[0]) / self.w[2]\n",
    "        y_right = (-self.w[1] - self.w[0]) / self.w[2]\n",
    "        plt.plot((-1,1), (y_left, y_right))\n",
    "        plt.gca().set_aspect(1)\n",
    "        plt.xlim([-1, 1])\n",
    "        plt.ylim([-1, 1])\n",
    "        plt.title(\"Candidate function found with PLA\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.219"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute the disagreement between f and g from PLA\n",
    "def pla_compare(pla, ds):\n",
    "    num_generations = 1000\n",
    "    wrong = 0\n",
    "    for i in range(num_generations):\n",
    "        test = generate_point()\n",
    "        # Prediction using f\n",
    "        fx = ds.target_function(test)\n",
    "        # Prediction using g\n",
    "        gx = pla.evaluate(test)\n",
    "        if fx != gx:\n",
    "            wrong += 1\n",
    "    return wrong/num_generations\n",
    "\n",
    "def svm_compare(clf, ds):\n",
    "    num_generations = 1000\n",
    "    wrong = 0\n",
    "    for i in range(num_generations):\n",
    "        test = generate_point()\n",
    "        # Prediction using f\n",
    "        fx = ds.target_function(test)\n",
    "        # Prediction using g\n",
    "        gx = clf.predict([test])\n",
    "        if fx != gx:\n",
    "            wrong += 1\n",
    "    return wrong/num_generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597145993413831"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_better = 0\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "\n",
    "    d = Data(10)\n",
    "    try:\n",
    "        pla = PLA(d)\n",
    "        pla.fit()\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(d.X, d.Y)\n",
    "        e_pla = pla_compare(pla, d)\n",
    "        e_csv = svm_compare(clf, d)\n",
    "\n",
    "        if e_csv > e_pla:\n",
    "            svm_better += 1\n",
    "        total += 1\n",
    "    except ValueError:\n",
    "        pass\n",
    "svm_better / total\n",
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0852"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Problem 9\n",
    "# Do this again, but N = 100. Also need to keep track of the number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.752 7.388\n"
     ]
    }
   ],
   "source": [
    "svm_better = 0\n",
    "total = 0\n",
    "vecs = 0\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        print (i)\n",
    "    d = Data(100)\n",
    "    try:\n",
    "        pla = PLA(d)\n",
    "        pla.fit()\n",
    "        clf = svm.SVC(C = 1000)\n",
    "        clf.fit(d.X, d.Y)\n",
    "        e_pla = pla_compare(pla, d)\n",
    "        e_csv = svm_compare(clf, d)\n",
    "\n",
    "        if e_csv > e_pla:\n",
    "            svm_better += 1\n",
    "        total += 1\n",
    "        vecs += len(clf.support_vectors_)\n",
    "    except ValueError:\n",
    "        pass\n",
    "print(svm_better / total, vecs / total)\n",
    "\n",
    "# E, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
