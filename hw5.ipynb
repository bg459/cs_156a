{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just solve the equation for $N$ given the initial conditions. Turns out to be roughly 45, so choose C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperbola is equation like x^2 - y^2, so we need w_1 to be positive, and w_2 to be negative. Choose E."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe VC dimension is 15 + 1, since there are 15 dimensions and this is the simple linear case. Choose D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial E}{\\partial u} = 2(ue^v - 2ve^{-u}) \\cdot (e^v + 2ve^u)$. Choose E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "u, v = 1, 1\n",
    "eta = 0.1\n",
    "def dU(u, v):\n",
    "    return 2 * (u * math.e ** v - 2 * v * math.e ** (-u)) * (math.e**v + 2*v*math.e**u)\n",
    "\n",
    "def dV(u, v):\n",
    "    return 2 * (u * math.e ** v - 2 * v * math.e ** (-u)) * (u * math.e ** v - 2 * math.e **(-u))\n",
    "\n",
    "def E(u, v):\n",
    "    return (u * math.e**v - 2 * v * math.e**(-u))**2\n",
    "\n",
    "error = 10000\n",
    "niters = 0\n",
    "while error > 10 ** (-14):\n",
    "    error = E(u, v)\n",
    "    v = v - eta * dV(u, v)\n",
    "    u = u - eta * dU(u, v)\n",
    "    niters += 1\n",
    "\n",
    "niters\n",
    "\n",
    "# I think python floats are double precision? So choose E. \n",
    "# For 6, choose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994036824006268\n",
      "0.21737358947642121\n",
      "0.11485537528459125\n",
      "0.21771153458640063\n",
      "0.13593872000593799\n"
     ]
    }
   ],
   "source": [
    "# These are the strangest answer choices ever. \n",
    "\n",
    "a = [1, 1]\n",
    "b = [0.713, 0.045]\n",
    "c = [0.016, 0.112]\n",
    "d = [-0.083, 0.029]\n",
    "e = [0.045, 0.024]\n",
    "\n",
    "def euclidean(u, v, n):\n",
    "    return (u - n[0])** 2 + (v - n[1]) **2\n",
    "\n",
    "for z in [a, b, c, d, e]:\n",
    "    print(euclidean(u, v, z))\n",
    "    \n",
    "# Choose C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    error = E(u, v)\n",
    "    v = v - eta * dV(u, v)\n",
    "    u = u - eta * dU(u, v)\n",
    "\n",
    "\n",
    "\n",
    "## Choose E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "Implementing the Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_point():\n",
    "    x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "    return (x, y)\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def target_function(self, x):\n",
    "        if x[0] * self.target_m + self.target_b > x[1]:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1    \n",
    "\n",
    "\n",
    "    def __init__(self, num_points):\n",
    "        p0 = generate_point()\n",
    "        p1 = generate_point()\n",
    "        self.target_m = (p1[1] - p0[1]) / (p1[0] - p0[0])\n",
    "        self.target_b = p0[1] - self.target_m * p0[0]\n",
    "\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i in range(num_points):\n",
    "            pt = generate_point()\n",
    "            self.X.append(pt)\n",
    "            self.Y.append(self.target_function(pt))\n",
    "\n",
    "    def plot(self):\n",
    "        cs = [\"red\" if y > 0 else \"blue\" for y in self.Y]\n",
    "        plt.scatter([x[0] for x in self.X], [x[1] for x in self.X], c=cs)\n",
    "        plt.plot((-1, 1), \n",
    "                 (-self.target_m+self.target_b, self.target_m+self.target_b))\n",
    "        plt.gca().set_aspect(1)\n",
    "        plt.xlim([-1, 1])\n",
    "        plt.ylim([-1, 1])\n",
    "        plt.title(\"Target function\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic ALgorithm\n",
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "class Logistic:\n",
    "    def evaluate(self, point):\n",
    "        return sigmoid(self.w[0] + self.w[1] * point[0] + self.w[2] * point[1])\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.w = [0, 0, 0]\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def fit(self):\n",
    "        eta = 0.01\n",
    "        self.w = np.array([0, 0, 0])\n",
    "        X = np.array(self.dataset.X)\n",
    "        N = X.shape[0]\n",
    "        x_0 = np.ones((N, 1))\n",
    "        X = np.concatenate((X, x_0), axis = 1)\n",
    "        \n",
    "        Y = self.dataset.Y\n",
    "        epochs = 0\n",
    "        while True:\n",
    "            prev = self.w\n",
    "            for choice in np.random.permutation(N):\n",
    "                choice = np.random.randint(0, N)\n",
    "                x = X[choice]\n",
    "                y = Y[choice]\n",
    "                gradE = (-1 * y * x) / (1 + np.exp(y * np.dot(self.w, x)))\n",
    "                self.w = self.w - eta * gradE\n",
    "                \n",
    "\n",
    "            if np.linalg.norm(self.w - prev) < 0.01:\n",
    "                print(epochs)\n",
    "                print(self.w)\n",
    "                return\n",
    "            \n",
    "            epochs += 1\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "[-4.68759276  6.12063737 -4.70243658]\n"
     ]
    }
   ],
   "source": [
    "data = Data(100)\n",
    "log = Logistic(data)\n",
    "log.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656444276253379"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Computing E_out\n",
    "\n",
    "def cross_entropy_error(w, x, y):\n",
    "    x = [1, x[0], x[1]]\n",
    "    return np.log(1 + np.exp(-1 * y * np.dot(w, x)))\n",
    "data = Data(2500)\n",
    "X = data.X\n",
    "errors = 0\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    answer = log.evaluate(x)\n",
    "    errors += cross_entropy_error(log.w, x, answer)\n",
    "errors/2500\n",
    "# Choose C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait we already did this! This is what we ran before. Choose A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLA chooses a point, and if y agree with x, it should do nothing. So basically, if a point N is correct, it should have no error at all (0). ONly E satisfies this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
